{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASS**: Naive Bayes SMS spam classifier using sklearn\n",
    "\n",
    "Data source: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## READING IN THE DATA\n",
    "\n",
    "# read tab-separated file using pandas\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('../data/sms.tsv',\n",
    "                   sep='\\t', header=None, names=['label', 'msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114bc12b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAERCAYAAAB1k2wJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJekxv0/mrm4Z3sv2qwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11531bba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the null accuracy rate\n",
    "df.label.value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       5572\n",
       "unique                      5169\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "Name: msg, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.msg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label to a quantitative binary variable\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44', 'cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# start with a simple example\n",
    "train_simple = ['call you tonight',\n",
    "                'Call me a cab',\n",
    "                'please call me... PLEASE 44!']\n",
    "\n",
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer()\n",
    "train_simple_dtm = vect.fit_transform(train_simple)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "train_simple_dtm = vect.transform(train_simple)\n",
    "train_simple_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>44</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   44  cab  call  me  please  tonight  you\n",
       "0   0    0     1   0       0        1    1\n",
       "1   0    1     1   1       0        0    0\n",
       "2   1    0     1   1       2        0    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(train_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>44</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   44  cab  call  me  please  tonight  you\n",
       "0   0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary, notice don't is missing)\n",
    "test_simple = [\"please don't call me\"]\n",
    "test_simple_dtm = vect.transform(test_simple)\n",
    "test_simple_dtm.toarray()\n",
    "pd.DataFrame(test_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 55209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REPEAT PATTERN WITH SMS DATA\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# learn vocabulary and create document-term matrix in a single step\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x7456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17604 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix\n",
    "test_dtm = vect.transform(X_test)\n",
    "test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['00',\n",
       "  '000',\n",
       "  '008704050406',\n",
       "  '0121',\n",
       "  '01223585236',\n",
       "  '01223585334',\n",
       "  '0125698789',\n",
       "  '02',\n",
       "  '0207',\n",
       "  '02072069400'],\n",
       " ['zed',\n",
       "  'zeros',\n",
       "  'zhong',\n",
       "  'zindgi',\n",
       "  'zoe',\n",
       "  'zoom',\n",
       "  'zouk',\n",
       "  'zyada',\n",
       "  'èn',\n",
       "  '〨ud'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store feature names and examine them\n",
    "train_features = vect.get_feature_names()\n",
    "len(train_features)\n",
    "train_features[:10], train_features[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert train_dtm to a regular array\n",
    "train_arr = train_dtm.toarray()\n",
    "# remember that each ROW is an sms\n",
    "# and each COLUMN is a token\n",
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SIMPLE SUMMARIES OF THE TRAINING DATA\n",
    "# refresher on numpy\n",
    "import numpy as np\n",
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(arr[0, :]) #sum of the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(arr[:,0]) # sum of the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "### EXERCISE ###\n",
    "################\n",
    "# count how many times the 0th token appears across ALL messages in train_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "### EXERCISE ###\n",
    "################\n",
    "# calculate the number of tokens in the 0th message in train_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(arr) # adds up all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(arr, axis=0) # adds up by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 26])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(arr, axis=1)  # adds up by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "### EXERCISE ###\n",
    "################\n",
    "# count how many times EACH token appears across ALL messages in train_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Darin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>1670</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>1660</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>1004</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>717</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>683</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count token\n",
       "6656   1670    to\n",
       "7420   1660   you\n",
       "6542   1004   the\n",
       "929     717   and\n",
       "3502    683    in"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with two columns, \"count\" and \"token\" that holds the token count for each token\n",
    "# use the numpy sum methods\n",
    "train_token_counts = pd.DataFrame({'token':train_features, 'count':np.sum(train_arr, axis=0)})\n",
    "train_token_counts.sort_index(by='count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MODEL BUILDING WITH NAIVE BAYES\n",
    "## http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "# train a Naive Bayes model using train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on test data using test_dtm\n",
    "preds = nb.predict(test_dtm)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988513998564\n",
      "[[1203    5]\n",
      " [  11  174]]\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to true labels\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, preds))\n",
    "print(metrics.confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986643100054\n"
     ]
    }
   ],
   "source": [
    "# predict (poorly calibrated) probabilities and calculate AUC\n",
    "probs = nb.predict_proba(test_dtm)[:, 1]\n",
    "probs\n",
    "print(metrics.roc_auc_score(y_test, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "### EXERCISE ###\n",
    "################\n",
    "# show the message text for the false positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "### EXERCISE ###\n",
    "################\n",
    "# show the message text for the false negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## COMPARE NAIVE BAYES AND LOGISTIC REGRESSION\n",
    "## USING ALL DATA AND CROSS-VALIDATION\n",
    "vect = CountVectorizer(ngram_range=(1,3), stop_words='english')\n",
    "# create a document-term matrix using all data\n",
    "all_dtm = vect.fit_transform(df.msg)\n",
    "\n",
    "# instantiate logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# compare AUC using cross-validation\n",
    "# note: this is slightly improper cross-validation... can you figure out why?\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513277 Seconds for logistic regression 0.976848539122\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "mean = cross_val_score(logreg, all_dtm, df.label, cv=10, scoring='accuracy').mean()\n",
    "print ((datetime.now()-now).total_seconds(), \"Seconds for logistic regression\", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.144102 Seconds for naive bayes 0.967516659054\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "mean = cross_val_score(nb, all_dtm, df.label, cv=10, scoring='accuracy').mean()\n",
    "print ((datetime.now()-now).total_seconds(), \"Seconds for naive bayes\", mean)\n",
    "# about 4 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Model evaluation metrics (confusion matrix, ROC/AUC)\n",
    "'''\n",
    "\n",
    "## READ DATA AND SPLIT INTO TRAIN/TEST\n",
    "\n",
    "# read in the data\n",
    "import pandas as pd\n",
    "data = pd.read_csv('../data/Default.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "X = data[['balance']]\n",
    "y = data.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict and calculate accuracy in one step\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict in one step, calculate accuracy in a separate step\n",
    "preds = logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare to null accuracy rate\n",
    "y_test.mean()\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CONFUSION MATRIX\n",
    "\n",
    "# print confusion matrix\n",
    "print metrics.confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nicer confusion matrix\n",
    "from nltk import ConfusionMatrix\n",
    "print ConfusionMatrix(list(y_test), list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sensitivity: percent of correct predictions when reference value is 'default'\n",
    "21 / float(58 + 21)\n",
    "print metrics.recall_score(y_test, preds)\n",
    "\n",
    "# specificity: percent of correct predictions when reference value is 'not default'\n",
    "print 2416 / float(2416 + 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "import matplotlib.pyplot as plt\n",
    "probs = logreg.predict_proba(X_test)[:, 1]\n",
    "plt.hist(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use 0.5 cutoff for predicting 'default'\n",
    "import numpy as np\n",
    "preds = np.where(probs > 0.5, 1, 0)\n",
    "print ConfusionMatrix(list(y_test), list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change cutoff for predicting default to 0.2\n",
    "preds = np.where(probs > 0.2, 1, 0)\n",
    "print ConfusionMatrix(list(y_test), list(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check accuracy, sensitivity, specificity\n",
    "print metrics.accuracy_score(y_test, preds)\n",
    "print 45 / float(34 + 45)\n",
    "print 2340 / float(2340 + 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ROC CURVES and AUC\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "print metrics.roc_auc_score(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use AUC as evaluation metric for cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "X = data[['balance']]\n",
    "y = data.default\n",
    "logreg = LogisticRegression()\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare to a model with an additional feature\n",
    "X = data[['balance', 'income']]\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC/AUC are very meaningful when:\n",
    "# 1. class sizes are inbalances\n",
    "# 2. comparing across different binary classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## BONUS: CALCULATE THE 'SPAMMINESS' OF EACH TOKEN\n",
    "\n",
    "\n",
    "# create separate DataFrames for ham and spam\n",
    "df_ham = df[df.label==0]\n",
    "df_spam = df[df.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn the vocabulary of ALL messages and save it\n",
    "vect = CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "vect.fit(df.msg)\n",
    "all_features = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create document-term matrix of ham, then convert to a regular array\n",
    "ham_dtm = vect.transform(df_ham.msg)\n",
    "ham_arr = ham_dtm.toarray()\n",
    "ham_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create document-term matrix of spam, then convert to a regular array\n",
    "spam_dtm = vect.transform(df_spam.msg)\n",
    "spam_arr = spam_dtm.toarray()\n",
    "spam_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL messages in ham_arr\n",
    "ham_counts = np.sum(ham_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL messages in spam_arr\n",
    "spam_counts = np.sum(spam_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "all_token_counts = pd.DataFrame({'token':all_features, 'ham':ham_counts, 'spam':spam_counts})\n",
    "all_token_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add one to ham counts and spam counts so that ratio calculations (below) make more sense\n",
    "all_token_counts['ham'] = all_token_counts.ham + 1\n",
    "all_token_counts['spam'] = all_token_counts.spam + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate ratio of spam-to-ham for each token\n",
    "all_token_counts['spam_ratio'] = all_token_counts.spam / all_token_counts.ham\n",
    "all_token_counts.sort_index(by='spam_ratio', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
